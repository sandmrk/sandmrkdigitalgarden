---
{"dg-publish":true,"dg-permalink":"/x/1557353083","permalink":"/x/1557353083/","title":"97ms 出声! 3 秒克隆你的音色!","tags":["AI","x-post","已整理","Qwen3-TTS","语音合成","AI模型","声音克隆","阿里巴巴"]}
---

# 97ms 出声! 3 秒克隆你的音色!

> **原推文**：[https://x.com/i/status/2014461755733508408](https://x.com/i/status/2014461755733508408) 
> **作者**：@未知作者
> **时间**：2026-1-23 11:29:55


### 💡 核心观点
97ms 出声! 3 秒克隆你的音色! 阿里通义千问刚刚开源了 Qwen3-TTS 一系列端到端的语音合成大模型. (去年九月份我给大家录过Qwen3-TTS-Flash 的测试). 这个模型由于足够小, 所以可以做到端到端延迟只有 97ms, 输入一个字就能开始出声! 传统 TTS 方案要么是 LM+DiT 级联架构有信息瓶颈, 要么延迟高不适合实时对话. Qwen3-TTS 用离散多码本 LM 架构直接端到端建模, 配合创新的双轨混合流式生成, 单一模型同时支持流式和非流式输出. 声音克隆也很猛, 只需要 3 秒的参考音频就能复刻音色. 还支持自然语言指令控制, 比如“用温柔鼓励的声音说”, 模型就能自适应调整语调、情感和韵律, 实现“所想即所听”.

### 🧵 深度展开



---


> [!AI-Summary] 元数据
> 作者：karminski-牙医 | 标签：Qwen3-TTS 语音合成 AI模型 声音克隆 阿里巴巴


> 阿里通义千问刚刚开源了 Qwen3-TTS 一系列端到端的语音合成大模型. (去年九月份我给大家录过Qwen3-TTS-Flash 的测试).  这个模型由于足够小, 所以可以做到端到端延迟只有 97ms, 输入一个字就能开始出声!

传统 TTS 方案要么是 LM+DiT 级联架构有信息瓶颈,



![封面](https://pbs.twimg.com/media/G_TOPD3WgAALjqx.jpg:large) 








---
**元数据** 
• 类型：推文  
• 标签：#AI 
• 收藏夹：资源 → X Posts/资源

